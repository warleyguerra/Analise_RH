
# Projeto de Análise de RH com Machine Learning ***Desafio do site analyticsvidhya***

## Introdução

Este projeto tem como objetivo analisar dados de Recursos Humanos utilizando técnicas de Machine Learning. O projeto é dividido em várias partes, cada uma focando em um aspecto diferente da análise de dados e modelagem.

## Sobre o problema prático: análise de RH
A análise de RH está revolucionando a forma como os departamentos de recursos humanos operam, levando a maior eficiência e melhores resultados em geral. Os recursos humanos usam análises há anos. No entanto, a recolha, o processamento e a análise de dados têm sido em grande parte manuais e, dada a natureza da dinâmica dos recursos humanos e dos KPI de RH, a abordagem tem restringido os RH. Portanto, é surpreendente que os departamentos de RH tenham acordado para a utilidade do aprendizado de máquina tão tarde no jogo. Esta é uma oportunidade de experimentar a análise preditiva para identificar os funcionários com maior probabilidade de serem promovidos.

## Índice

- [Parte 1: Tratamento de Dados e Modelagem Inicial](https://github.com/warleyguerra/Analise_RH/blob/main/parte1.ipynb)
- [Parte 2: Tratando o Desbalanceamento de Dados](https://github.com/warleyguerra/Analise_RH/blob/main/parte2.ipynb)
- [Parte 3: Ajuste de Hiperparâmetros e Modelos Simples](https://github.com/warleyguerra/Analise_RH/blob/main/parte3.ipynb)
- [Final: Comparação e Conclusão](https://github.com/warleyguerra/Analise_RH/blob/main/Final.ipynb)

## Parte 1: Tratamento de Dados e Modelagem Inicial

### Descrição

O notebook `parte1.ipynb` foca no tratamento inicial dos dados e na modelagem inicial para um projeto de análise de RH. Ele começa importando várias bibliotecas essenciais e os dados necessários.

#### Principais Etapas

1. **Importação de Bibliotecas e Dados**
2. **Tratamento de Dados**
3. **Modelagem Inicial**
4. **Aplicação do Modelo em Dados de Teste**

### Conclusão

O notebook serve como uma introdução ao projeto, abordando as etapas iniciais de tratamento de dados e a aplicação de um modelo de machine learning.

## Parte 2: Tratando o Desbalanceamento de Dados

### Descrição

O notebook `parte2.ipynb` se concentra no tratamento do desbalanceamento de dados e na modelagem subsequente.

#### Principais Etapas

1. **Importação de Bibliotecas e Dados**
2. **Tratamento de Dados**
3. **Balanceamento de Dados**
4. **Modelagem com Dados Balanceados**

### Conclusão

Este notebook foca em tratar o problema de desbalanceamento de dados e treinar um modelo de Árvore de Decisão.

## Parte 3: Ajuste de Hiperparâmetros e Modelos Simples

### Descrição

O notebook `parte3.ipynb` explora o ajuste de hiperparâmetros e a utilização de modelos mais simples para evitar o problema de overfitting.

#### Principais Etapas

1. **Importação de Bibliotecas e Dados**
2. **Tratamento de Dados**
3. **Ajuste de Hiperparâmetros**
4. **Modelos Simples**

### Conclusão

Este notebook se foca em otimizar os modelos anteriores através do ajuste de hiperparâmetros e da utilização de modelos mais simples para evitar overfitting.

## Final: Comparação e Conclusão

### Descrição

O notebook `Final.ipynb` serve como um resumo e comparação das abordagens tomadas nos notebooks anteriores.

#### Principais Etapas

1. **Importação de Bibliotecas e Dados**
2. **Comparação de Modelos**
3. **Escolha do Modelo Final**

### Conclusão

O notebook `Final.ipynb` serve como um resumo e ponto de comparação para as abordagens tomadas nas partes anteriores.

## Sobre o F1-Score de 0.48

Para fornecer uma explicação abrangente sobre por que um F1-Score de 0.48 é bom no contexto deste projeto, é importante considerar vários fatores:

### Competitividade

O melhor desempenho na competição foi de 0.53 e o modelo desenvolvido alcançou 0.48. Isso coloca o modelo como altamente competitivo, especialmente se muitos participantes estiverem envolvidos.

### Desbalanceamento de Dados

O projeto foca no tratamento do desbalanceamento de dados, um desafio comum em modelagem de machine learning. Conseguir um F1-Score relativamente alto em um conjunto de dados desbalanceado é um feito notável.

### Complexidade do Modelo

Foram exploradas técnicas para o ajuste de hiperparâmetros e utilizados modelos mais simples para evitar overfitting. Isso indica que o F1-Score foi otimizado e não é um resultado de um modelo overfitado.

### Variedade de Modelos Testados

O projeto não se limitou a um único tipo de modelo, mas tentou várias abordagens, desde Redes Neurais até Árvores de Decisão. Isso torna o F1-Score de 0.48 mais confiável como uma métrica de desempenho geral.

### Iteração e Refinamento

O projeto passou por várias iterações de modelagem e avaliação, cada uma focando em aspectos diferentes como balanceamento de dados e ajuste de hiperparâmetros. Isso sugere que o F1-Score foi alcançado após considerável refinamento e otimização.

### Conclusão e Comparação Final

O notebook final faz uma comparação direta entre os diferentes modelos e abordagens testados, consolidando o F1-Score como uma métrica de desempenho significativa.

### Próximos Passos

Mesmo que 0.48 seja um bom resultado, o projeto já está planejando como melhorar ainda mais esse número, o que mostra uma abordagem equilibrada para a solução de problemas.
